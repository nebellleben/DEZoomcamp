{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1fdfa55",
   "metadata": {},
   "source": [
    "## Test Injection of Data\n",
    "\n",
    "- This note book try to import parquet file into postgreSQL database\n",
    "- Remember to implement the click part to take in command line parameters\n",
    "- When done it will be converted to script using nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb3ed9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a671f3a4b5c4ff3933d3355dffaaf18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
      "0         2  2025-11-01 00:34:48   2025-11-01 00:41:39                  N   \n",
      "1         2  2025-11-01 00:18:52   2025-11-01 00:24:27                  N   \n",
      "2         2  2025-11-01 01:03:14   2025-11-01 01:15:24                  N   \n",
      "3         2  2025-11-01 00:10:57   2025-11-01 00:24:53                  N   \n",
      "4         1  2025-11-01 00:03:48   2025-11-01 00:19:38                  N   \n",
      "\n",
      "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
      "0         1.0            74            42              1.0           0.74   \n",
      "1         1.0            74            42              2.0           0.95   \n",
      "2         1.0            83           160              1.0           2.19   \n",
      "3         1.0           166           127              1.0           5.44   \n",
      "4         1.0           166           262              1.0           3.20   \n",
      "\n",
      "   fare_amount  ...  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
      "0          7.2  ...      0.5        1.94           0.0        NaN   \n",
      "1          7.2  ...      0.5        0.00           0.0        NaN   \n",
      "2         13.5  ...      0.5        5.00           0.0        NaN   \n",
      "3         24.7  ...      0.5        0.50           0.0        NaN   \n",
      "4         18.4  ...      1.5        1.00           0.0        NaN   \n",
      "\n",
      "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
      "0                    1.0         11.64           1.0        1.0   \n",
      "1                    1.0          9.70           2.0        1.0   \n",
      "2                    1.0         21.00           1.0        1.0   \n",
      "3                    1.0         27.70           1.0        1.0   \n",
      "4                    1.0         24.65           1.0        1.0   \n",
      "\n",
      "   congestion_surcharge  cbd_congestion_fee  \n",
      "0                  0.00                 0.0  \n",
      "1                  0.00                 0.0  \n",
      "2                  0.00                 0.0  \n",
      "3                  0.00                 0.0  \n",
      "4                  2.75                 0.0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#import click\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm.auto import tqdm\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "parquet_path = \"./green_tripdata_2025-11.parquet\"\n",
    "\n",
    "pg_user = 'postgres'\n",
    "pg_pass = 'postgres'\n",
    "pg_host = 'localhost'\n",
    "pg_port = '5433'\n",
    "pg_db = 'ny_taxi'\n",
    "\n",
    "target_table = 'green_taxi_trips'\n",
    "\n",
    "engine = create_engine(f'postgresql://{pg_user}:{pg_pass}@{pg_host}:{pg_port}/{pg_db}')\n",
    "\n",
    "first = True\n",
    "preview_df = None\n",
    "\n",
    "parquet_file = pq.ParquetFile(parquet_path)\n",
    "\n",
    "for batch in tqdm(parquet_file.iter_batches(batch_size=100000)):\n",
    "    df_chunk = batch.to_pandas()\n",
    "\n",
    "    if first:\n",
    "        df_chunk.head(0).to_sql(\n",
    "            name=target_table,\n",
    "            con=engine,\n",
    "            if_exists='replace'\n",
    "        )\n",
    "        preview_df = df_chunk.head()\n",
    "        first = False\n",
    "\n",
    "    df_chunk.to_sql(\n",
    "        name=target_table,\n",
    "        con=engine,\n",
    "        if_exists='append'\n",
    "    )\n",
    "\n",
    "if preview_df is not None:\n",
    "    print(preview_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
